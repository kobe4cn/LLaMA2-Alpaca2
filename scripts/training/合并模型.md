### æ¨¡å‹åˆå¹¶è„šæœ¬è°ƒç”¨æ–¹å¼
### åˆå¹¶ chinese-llama-2-lora-7bä¸LLaMa2 hf
python scripts/merge_llama2_with_chinese_lora_low_mem.py \
--base_model /mnt/mydisk/llama2_models/Llama-2-7b-hf/ \
--lora_model /mnt/mydisk/llama2_models/chinese-llama-2-lora-7b/ \
--output_dir /mnt/mydisk/llama2-merage-output/merge-llama2-chinese-lora-7B/ \
--output_type huggingface

### LLaMa2å¼€å§‹ä¸æ”¯æŒå¤šä¸ªloraæ¨¡å‹åˆå¹¶åˆ°åŸå§‹çš„LLaMa2 hfæ¨¡å‹ä¸Šï¼Œåªèƒ½LLama2åŸå§‹æ¨¡å‹ä¸chinese-llama-2-lora-7bæˆ–è€…ä¸chinese-alpaca-2-lora-7b ç”Ÿæˆæ–°çš„åˆå¹¶æ¨¡å‹

### åˆå¹¶ chinese-alpaca-2-lora-7bä¸LLaMa2 hf
python scripts/merge_llama2_with_chinese_lora_low_mem.py \
--base_model /mnt/mydisk/llama2_models/Llama-2-7b-hf/ \
--lora_model /mnt/mydisk/llama2_models/chinese-alpaca-2-lora-7b/ \
--output_dir /mnt/mydisk/llama2-merage-output/merge-llama2-chinese-alpaca-7B/ \
--output_type huggingface


æ‰‹åŠ¨æ¨¡å‹åˆå¹¶ä¸è½¬æ¢

ä»¥ä¸‹ä»‹ç»äº†æ‰‹åŠ¨å°†LoRAä¸åŸç‰ˆLlama-2åˆå¹¶å¾—åˆ°å®Œæ•´æ¨¡å‹çš„æµç¨‹ã€‚å¦‚ç½‘ç»œå¸¦å®½å……è¶³ï¼Œå»ºè®®ç›´æ¥ä¸‹è½½å®Œæ•´ç‰ˆæ¨¡å‹ã€‚

å‡†å¤‡å·¥ä½œ

è¿è¡Œå‰ç¡®ä¿æ‹‰å–ä»“åº“æœ€æ–°ç‰ˆä»£ç ï¼šgit pull
ç¡®ä¿æœºå™¨æœ‰è¶³å¤Ÿçš„å†…å­˜åŠ è½½å®Œæ•´æ¨¡å‹ï¼ˆä¾‹å¦‚7Bæ¨¡å‹éœ€è¦13-15Gï¼‰ä»¥è¿›è¡Œåˆå¹¶æ¨¡å‹æ“ä½œ
å®‰è£…ä¾èµ–åº“ï¼ˆé¡¹ç›®æ ¹ç›®å½•requirements.txtï¼‰ï¼š
$ pip install -r requirements.txt
Step 1: è·å–åŸç‰ˆLlama-2-hfæ¨¡å‹

åŸç‰ˆLlama-2-hfåœ°å€ï¼šhttps://huggingface.co/meta-llama/Llama-2-7b-hf

HFæ ¼å¼æ¨¡å‹ç›¸å…³æ–‡ä»¶ï¼ˆå¯ä»¥ä¸ç”¨ä¸‹è½½safetensorsæ ¼å¼æ¨¡å‹æƒé‡ï¼‰ï¼š

config.json
generation_config.json
pytorch_model-00001-of-00002.bin
pytorch_model-00002-of-00002.bin
pytorch_model.bin.index.json
special_tokens_map.json
tokenizer_config.json
tokenizer.json
tokenizer.model
Step 2: åˆå¹¶LoRAæƒé‡ï¼Œç”Ÿæˆå…¨é‡æ¨¡å‹æƒé‡

è¿™ä¸€æ­¥éª¤ä¼šåˆå¹¶LoRAæƒé‡ï¼Œç”Ÿæˆå…¨é‡æ¨¡å‹æƒé‡ã€‚æ­¤å¤„å¯ä»¥é€‰æ‹©è¾“å‡ºPyTorchç‰ˆæœ¬æƒé‡ï¼ˆ.pthæ–‡ä»¶ï¼‰æˆ–è€…è¾“å‡ºHuggingFaceç‰ˆæœ¬æƒé‡ï¼ˆ.binæ–‡ä»¶ï¼‰ã€‚æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

$ python scripts/merge_llama2_with_chinese_lora_low_mem.py \
    --base_model path_to_original_llama2_hf_dir \
    --lora_model path_to_chinese_llama2_or_alpaca2_lora \
    --output_type huggingface \
    --output_dir path_to_output_dir 
å‚æ•°è¯´æ˜ï¼š

--base_modelï¼šå­˜æ”¾HFæ ¼å¼çš„Llama-2æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶çš„ç›®å½•
--lora_modelï¼šä¸­æ–‡LLaMA-2/Alpaca-2 LoRAè§£å‹åæ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼Œä¹Ÿå¯ä½¿ç”¨ğŸ¤—Model Hubæ¨¡å‹è°ƒç”¨åç§°ï¼ˆä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰
--output_typeï¼šæŒ‡å®šè¾“å‡ºæ ¼å¼ï¼Œå¯ä¸ºpthæˆ–huggingfaceã€‚è‹¥ä¸æŒ‡å®šï¼Œé»˜è®¤ä¸ºhuggingface
--output_dirï¼šæŒ‡å®šä¿å­˜å…¨é‡æ¨¡å‹æƒé‡çš„ç›®å½•ï¼Œé»˜è®¤ä¸º./
ï¼ˆå¯é€‰ï¼‰--verboseï¼šæ˜¾ç¤ºåˆå¹¶è¿‡ç¨‹ä¸­çš„è¯¦ç»†ä¿¡æ¯